{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sem Pormpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.schema import SystemMessage\n",
    "import numpy as np\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (901995009.py, line 13)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mseparators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"]\u001b[39m\n               ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "#Carregar PDF\n",
    "file = \"files/Configuração e teste - Central SensorGW.pdf\"\n",
    "loader = PyMuPDFLoader(file)\n",
    "docs = loader.load()\n",
    "\n",
    "# Extrair texto dos documentos\n",
    "texts = []\n",
    "for doc in docs:\n",
    "    texts.append(doc.page_content)\n",
    "    \n",
    "#Text Splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"],\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "split_texts = text_splitter.split_documents(docs)\n",
    "\n",
    "\n",
    "#Verificando se foi extraido corretamente\n",
    "print(split_texts[0])\n",
    "\n",
    "#Embbeding e Vector Store\n",
    "embedding_model = OpenAIEmbeddings()\n",
    "vector_store = FAISS.from_documents(\n",
    "    documents=split_texts,\n",
    "    embedding=embedding_model\n",
    ")\n",
    "\n",
    "#Retriver\n",
    "retriever = vector_store.as_retriever()\n",
    "# Preparar o contexto\n",
    "pergunta = \"Como faço para congifurar a central para o cliente?\"\n",
    "docs_relevantes = retriever.invoke(pergunta)\n",
    "context_list = []\n",
    "for doc in docs_relevantes:\n",
    "    context_list.append(doc.page_content)\n",
    "\n",
    "context = \"\\n\\n\".join(context_list)\n",
    "#Instanciando o modelo de IA e enviando a pergunta\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo-0125\",\n",
    "    temperature=0,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Baseado no seguinte contexto:\\n\\n{context}\\n\\nResponda à pergunta: {pergunta}\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "#Resposta\n",
    "print(completion.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Com Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Para configurar a central para o cliente, siga os passos abaixo:\n",
       "\n",
       "1. **Configuração Inicial da Central:**\n",
       "   - Acesse o PUTTY.\n",
       "   - Execute os seguintes comandos:\n",
       "     ```bash\n",
       "     sensorgw appConfig\n",
       "     Default server configuration? (y or n): y\n",
       "     Client WebApp: \"TESTE\"\n",
       "     Client Login:\n",
       "     Client Password:\n",
       "     CheckConnection:\n",
       "     CheckModem:\n",
       "     Carrier: \"operadora\"\n",
       "     \n",
       "     sync\n",
       "     sensorgw stop\n",
       "     ```\n",
       "\n",
       "2. **Configuração do Hamachi:**\n",
       "   - Continuando no PUTTY, execute os seguintes comandos para o Hamachi:\n",
       "     ```\n",
       "     /etc/init.d/logmein-hamachi stop\n",
       "     rm -Rf /var/lib/logmein-hamachi/\n",
       "     /etc/init.d/logmein-hamachi start\n",
       "     hamachi login\n",
       "     hamachi set-nick \"CLIENTE\"\n",
       "     hamachi attach eduardosleal@mcasistemas.com.br\n",
       "     hamachi do-join 158-893-675 (Senha: mcaUser)\n",
       "     ```\n",
       "\n",
       "3. **Adicionar Verificação de Configuração dos Arquivos .xml:**\n",
       "   - Execute o procedimento de verificação dos arquivos .xml essenciais à central.\n",
       "\n",
       "4. **Cadastro da Central no Device Manager:**\n",
       "   - Acesse o [link do Device Manager](http://dm.sensorweb.com.br/login).\n",
       "   - Clique em \"CENTRAIS\" na página principal.\n",
       "   - Insira as informações de rede da central para IP Dinâmico (D.H.C.P) seguindo as instruções do portal.\n",
       "   - Faça login com as credenciais:\n",
       "     - Login: teste\n",
       "     - Senha: teste\n",
       "   - Teste se a bateria mantém o hardware em funcionamento sem a fonte, desconectando a fonte da central.\n",
       "   - Teste o botão ON/OFF da Central:\n",
       "     - Um clique desliga a central.\n",
       "     - Mantendo o botão pressionado, force o desligamento.\n",
       "\n",
       "Ao seguir esses passos, você configurou a central para o cliente e a vinculou ao Device Manager para controle de estoque e suporte remoto."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Carregar PDF\n",
    "file = \"files/Configuração e teste - Central SensorGW.pdf\"\n",
    "loader = PyMuPDFLoader(file)\n",
    "docs = loader.load()\n",
    "\n",
    "# Extrair texto dos documentos\n",
    "texts = []\n",
    "for doc in docs:\n",
    "    texts.append(doc.page_content)\n",
    "    \n",
    "# Text Splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    sseparators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"],\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "split_texts = text_splitter.create_documents(texts)\n",
    "\n",
    "# Embedding e Vector Store\n",
    "embedding_model = OpenAIEmbeddings()\n",
    "vector_store = FAISS.from_documents(\n",
    "    documents=split_texts,\n",
    "    embedding=embedding_model\n",
    ")\n",
    "\n",
    "# Retriever\n",
    "retriever = vector_store.as_retriever()\n",
    "\n",
    "# Pegar os documentos relevantes baseado na pergunta\n",
    "pergunta = \"Como faço para congifurar a central para o cliente?\"\n",
    "docs_relevantes = retriever.invoke(pergunta)\n",
    "\n",
    "# Preparar o contexto\n",
    "context_list = []\n",
    "for doc in docs_relevantes:\n",
    "    context_list.append(doc.page_content)\n",
    "\n",
    "context = \"\\n\\n\".join(context_list)\n",
    "\n",
    "# Instanciando o modelo de IA e enviando a pergunta\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo-0125\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \n",
    "         \"content\": f\"Use apenas as informações abaixo para responder a pergunta do usuário. Seja detalhado, em formato de passo a passo.\\n\\n{context}\"\n",
    "         },\n",
    "        {\"role\": \"user\", \n",
    "        \"content\": f\"Baseado no seguinte contexto:\\n\\n{context}\\n\\nResponda à pergunta: {pergunta}\"\n",
    "         } \n",
    "    ]\n",
    ")\n",
    "\n",
    "# Resposta\n",
    "display(Markdown(completion.choices[0].message.content))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Com Hyde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Para configurar a central para o cliente, siga os passos abaixo:\n",
       "\n",
       "1. **Acessar o PUTTY para configurar a central**:\n",
       "    - Abra o terminal PUTTY.\n",
       "\n",
       "2. **Realizar a configuração da central para o envio dos dados ao portal do cliente**:\n",
       "    - Digite o comando: `sensorgw appConfig`\n",
       "    - Quando perguntado se é a configuração padrão do servidor, responda com `y`.\n",
       "    - Preencha as informações solicitadas, como:\n",
       "        - Nome do Client WebApp: \"TESTE\"\n",
       "        - Client Login (preencher quando solicitado)\n",
       "        - Client Password (preencher quando solicitado)\n",
       "        - CheckConnection\n",
       "        - CheckModem\n",
       "        - Carrier: \"operadora\"\n",
       "\n",
       "3. **Sincronizar e parar o serviço**:\n",
       "    - Digite os comandos:\n",
       "        - `sync`\n",
       "        - `sensorgw stop`\n",
       "\n",
       "4. **Configurar o HAMACHI**:\n",
       "    - Continue no terminal PUTTY e execute os seguintes comandos:\n",
       "    - Parar o serviço do HAMACHI: `/etc/init.d/logmein-hamachi stop`\n",
       "    - Remover configurações prévias do HAMACHI: `rm -Rf /var/lib/logmein-hamachi/`\n",
       "    - Iniciar o serviço do HAMACHI: `/etc/init.d/logmein-hamachi start`\n",
       "    \n",
       "5. **Realizar o LOGIN do HAMACHI**:\n",
       "    - Execute: `hamachi login`\n",
       "\n",
       "6. **Definir o nome da central no HAMACHI**:\n",
       "    - Para definir o nome, utilize o comando: `hamachi set-nick “CLIENTE”`\n",
       "\n",
       "7. **Vincular a conta do HAMACHI**:\n",
       "    - Use o comando: `hamachi attach eduardosleal@mcasistemas.com.br`\n",
       "\n",
       "8. **Conectar na conta do HAMACHI**:\n",
       "    - Digite: `hamachi do-join 158-893-675`\n",
       "    - Insira a senha: `mcaUser`\n",
       "\n",
       "9. **Configurar o IP da central para IP Dinâmico (D.H.C.P)**:\n",
       "    - No navegador, acesse o IP da central.\n",
       "    - Faça o login usando as credenciais fornecidas na central.\n",
       "\n",
       "10. **Testar a bateria da central**:\n",
       "    - Desconecte a fonte da central e verifique se a bateria mantém o hardware em funcionamento.\n",
       "\n",
       "11. **Testar botão ON/OFF da central**:\n",
       "    - Certifique-se de que a central desliga com um clique e, caso necessário, teste o modo forçado de desligamento mantendo o botão pressionado.\n",
       "\n",
       "Esses passos permitem configurar a central para o cliente, garantindo que esteja conectada e pronta para enviar os dados para o portal do cliente."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Carregar PDF\n",
    "file = \"files/Configuração e teste - Central SensorGW.pdf\"\n",
    "loader = PyMuPDFLoader(file)\n",
    "docs = loader.load()\n",
    "\n",
    "# Dividir o texto\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\\n\",\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "split_texts = text_splitter.split_documents(docs)\n",
    "\n",
    "# Criar embeddings e armazenar em um vetor\n",
    "embedding_model = OpenAIEmbeddings()\n",
    "vector_store = FAISS.from_documents(documents=split_texts, embedding=embedding_model)\n",
    "retriever = vector_store.as_retriever()\n",
    "\n",
    "# Definir a pergunta\n",
    "pergunta = \"Como é faço para configurar a central para o cliente?\"\n",
    "hyde_model = ChatOpenAI(\n",
    "    model_name=\"gpt-3.5-turbo-0125\", \n",
    "    temperature=0\n",
    ")\n",
    "hyde_prompt = f\"\"\"\n",
    "Responda à seguinte pergunta de forma detalhada e clara. Seja preciso e forneça uma explicação passo a passo:\n",
    "\n",
    "Pergunta: {pergunta}\n",
    "\n",
    "Utilize as informações abaixo para criar uma resposta completa:\n",
    "\"\"\"\n",
    "resposta_hipotetica = hyde_model.invoke([SystemMessage(content=hyde_prompt)])\n",
    "\n",
    "# Criar embedding da resposta hipotética para busca mais precisa\n",
    "resposta_hipotetica_embedding = embedding_model.embed_query(resposta_hipotetica.content)\n",
    "\n",
    "# Criar embedding da pergunta original para busca mais precisa\n",
    "pergunta_embedding = embedding_model.embed_query(pergunta)\n",
    "\n",
    "# Garantir que ambos os embeddings sejam numpy arrays\n",
    "pergunta_embedding = np.array(pergunta_embedding)\n",
    "resposta_hipotetica_embedding = np.array(resposta_hipotetica_embedding)\n",
    "\n",
    "# Combinar os embeddings da pergunta original e da resposta hipotética\n",
    "combined_embedding = (pergunta_embedding + resposta_hipotetica_embedding) / 2\n",
    "\n",
    "# Buscar documentos com o embedding combinado\n",
    "retrieved_docs = vector_store.similarity_search_by_vector(combined_embedding)\n",
    "\n",
    "# Criar o contexto com os documentos recuperados\n",
    "context_list = []\n",
    "for doc in retrieved_docs:\n",
    "    context_list.append(doc.page_content)\n",
    "\n",
    "# Juntar os contextos recuperados em uma única string\n",
    "context = \"\\n\\n\".join(context_list)\n",
    "\n",
    "# Gerar a resposta final com base no contexto recuperado\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo-0125\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": f\"Use apenas as informações abaixo para responder a pergunta do usuário. Seja detalhado e em formato de passo a passo.\\n\\n{context}\"},\n",
    "        {\"role\": \"user\",\"content\": f\"Baseado no seguinte contexto:\\n\\n{context}\\n\\nResponda à pergunta: {pergunta}\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Exibir a resposta gerada\n",
    "display(Markdown(completion.choices[0].message.content))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
