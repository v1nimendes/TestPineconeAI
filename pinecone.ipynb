{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "from pinecone import Pinecone\n",
    "from IPython.display import display, Markdown\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from openai import OpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain.chains import RetrievalQA, RetrievalQAWithSourcesChain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "pc = Pinecone(api_key)\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"ia-sensor\"\n",
    "\n",
    "if not pc.has_index(index_name):\n",
    "   pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=1536,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(\n",
    "            cloud='aws',\n",
    "            region='us-east-1'\n",
    "        )\n",
    "    )\n",
    "    \n",
    "while not pc.describe_index(index_name).status['ready']:\n",
    "    time.sleep(1)\n",
    "\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sem prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sensorweb2\\AppData\\Local\\Temp\\ipykernel_18700\\979736543.py:60: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  resposta = llm(pergunta_com_contexto)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Para configurar a central para o cliente, você pode seguir os seguintes passos:\n",
       "\n",
       "1. Acesse o PUTTY e execute o comando sensorgw appConfig.\n",
       "2. Confirme a configuração padrão do servidor.\n",
       "3. Insira o nome do cliente no campo Client WebApp.\n",
       "4. Preencha os campos Client Login e Client Password.\n",
       "5. Verifique a conexão com o CheckConnection e CheckModem.\n",
       "6. Defina a operadora no campo Carrier.\n",
       "7. Salve as configurações com o comando sync.\n",
       "8. Pare o serviço com sensorgw stop.\n",
       "\n",
       "Além disso, você pode configurar o HAMACHI seguindo os passos:\n",
       "1. Pare o serviço do HAMACHI com /etc/init.d/logmein-hamachi stop.\n",
       "2. Remova as configurações prévias do HAMACHI com rm -Rf /var/lib/logmein-hamachi/.\n",
       "3. Inicie o serviço do HAMACHI com /etc/init.d/logmein-hamachi start.\n",
       "4. Faça o login no HAMACHI com hamachi login.\n",
       "5. Defina o nome da central para o HAMACHI com hamachi set-nick.\n",
       "6. Vincule a conta do HAMACHI com hamachi attach.\n",
       "7. Conecte na conta do HAMACHI com hamachi do-join.\n",
       "\n",
       "Esses são alguns passos básicos para configurar a central para o cliente. Lembre-se de sempre verificar as especificidades do cliente e adaptar as configurações conforme necessário."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Upload do PDFs\n",
    "file = \"files/Configuração e teste - Central SensorGW.pdf\"\n",
    "loader = PyMuPDFLoader(file)\n",
    "docs = loader.load()\n",
    "\n",
    "# Extrair texto dos documentos\n",
    "texts = []\n",
    "for doc in docs:\n",
    "    texts.append(doc.page_content)\n",
    "\n",
    "# Dividir texto em chunks\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\\n\",\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "split_texts = text_splitter.split_documents(docs)\n",
    "\n",
    "# Gera embeddings\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# Criação do armazenamento vetorial no Pinecone\n",
    "vectorstore = PineconeVectorStore.from_documents(\n",
    "    documents=split_texts, \n",
    "    embedding=embeddings, \n",
    "    index_name=index_name \n",
    ")\n",
    "\n",
    "# Configuração do modelo\n",
    "llm = ChatOpenAI(   \n",
    "    model='gpt-3.5-turbo',  \n",
    "    temperature=0.0  \n",
    ")  \n",
    "\n",
    "#  Configuração de mecanismo de perguntas e respostas\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(  \n",
    "    llm=llm,  \n",
    "    chain_type=\"stuff\",  \n",
    "    retriever=vectorstore.as_retriever()  \n",
    ")  \n",
    "\n",
    "qa_with_sources = RetrievalQAWithSourcesChain.from_chain_type(  \n",
    "    llm=llm,  \n",
    "    chain_type=\"stuff\",  \n",
    "    retriever=vectorstore.as_retriever()  \n",
    ")\n",
    "\n",
    "contexto = \"\\n\".join(texts) \n",
    "\n",
    "# Consulta para buscar informações\n",
    "pergunta = \"Como faço para congifurar a central para o cliente?\"\n",
    "\n",
    "pergunta_com_contexto = f\"Contexto:\\n{contexto}\\n\\nPergunta: {pergunta}\"\n",
    "\n",
    "resposta = llm(pergunta_com_contexto)\n",
    "\n",
    "display(Markdown(resposta.content)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Com prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Para configurar a central para o cliente, siga os seguintes passos:\n",
       "\n",
       "1. Acesse o PUTTY com o IP da central em teste e faça o login com as credenciais:\n",
       "   - Login as: root\n",
       "   - Password: mcaUser\n",
       "\n",
       "2. Verifique a versão da Central utilizando o comando:\n",
       "   ```\n",
       "   $ sensorgw version\n",
       "   ```\n",
       "\n",
       "3. Caso seja necessário atualizar a versão da Central, utilize o comando de atualização correspondente à versão atual da Central, conforme a lista de comandos de atualização fornecida no contexto.\n",
       "\n",
       "4. Após atualizar a versão, reinicie a central com o comando:\n",
       "   ```\n",
       "   $ reboot\n",
       "   ```\n",
       "\n",
       "5. Teste o BUZZER com o comando:\n",
       "   ```\n",
       "   $ beep -l 300\n",
       "   ```\n",
       "\n",
       "6. Teste o RTC (Relógio em Tempo Real) com os comandos:\n",
       "   - Para verificar a hora atual: \n",
       "     ```\n",
       "     $ hwclock -r\n",
       "     ```\n",
       "   - Para atualizar o RTC: \n",
       "     ```\n",
       "     $ hwclock -w\n",
       "     ```\n",
       "\n",
       "7. Verifique se o GATEWAY \"DEBUG\" está funcionando corretamente, observando a leitura de transmissores, repetidores e informações do GATEWAY pela central, utilizando o comando:\n",
       "   ```\n",
       "   $ tail -100f /home/sensorgw/application/conf/data/log_dac_win_service.log\n",
       "   ```\n",
       "\n",
       "8. Para configurar a conexão do modem, siga os passos específicos para a versão do hardware da Central:\n",
       "   - Para Central Lizzy (hardware 2.0):\n",
       "     ```\n",
       "     $ sensorgw modem easy_on\n",
       "     $ pon operadora\n",
       "     $ tail -f /var/log/messages\n",
       "     $ ping -I ppp0 clientes.sensorweb.com.br\n",
       "     $ poff -a\n",
       "     ```\n",
       "\n",
       "9. Teste a conexão do modem com os comandos:\n",
       "   ```\n",
       "   $ sensorgw modemCheck\n",
       "   $ sensorgw switchOnModem\n",
       "   ```\n",
       "\n",
       "10. Verifique o GPIO para garantir que o pino 7 esteja ligado, utilizando os comandos:\n",
       "    ```\n",
       "    $ gpio readall\n",
       "    $ sensorgw switchOffModem\n",
       "    $ gpio readall\n",
       "    $ sensorgw switchOnModem\n",
       "    ```\n",
       "\n",
       "11. Realize o teste do DIAGNÓSTICO com um Pendrive na entrada USB de cima e aguarde o BEEP de confirmação ao atingir 100% no display.\n",
       "\n",
       "12. Configure a central para as configurações padrões com os comandos:\n",
       "    ```\n",
       "    $ sensorgw appConfig\n",
       "    $ sensorgw stop\n",
       "    $ pidof java\n",
       "    ```\n",
       "\n",
       "13. Defina as informações de rede da central para IP Dinâmico (D.H.C.P) e acesse o navegador com o IP da central, utilizando as credenciais fornecidas.\n",
       "\n",
       "14. Teste se a bateria mantém o hardware em funcionamento sem a fonte, desconectando a fonte da central.\n",
       "\n",
       "15. Teste o botão ON/OFF da Central para garantir seu funcionamento adequado.\n",
       "\n",
       "16. Feche o gabinete da central, limpe a superfície e insira os adesivos conforme necessário.\n",
       "\n",
       "Lembre-se de seguir todos os passos com atenção e garantir que cada etapa seja concluída corretamente antes de prosseguir para a próxima."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Upload do PDFs\n",
    "file = \"files/Configuração e teste - Central SensorGW.pdf\"\n",
    "loader = PyMuPDFLoader(file)\n",
    "docs = loader.load()\n",
    "\n",
    "# Extrair texto dos documentos\n",
    "texts = []\n",
    "for doc in docs:\n",
    "    texts.append(doc.page_content)\n",
    "\n",
    "# Dividir texto em chunks\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\\n\",\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "split_texts = text_splitter.split_documents(docs)\n",
    "\n",
    "# Gera embeddings\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# Criação do armazenamento vetorial no Pinecone\n",
    "vectorstore = PineconeVectorStore.from_documents(\n",
    "    documents=split_texts, \n",
    "    embedding=embeddings, \n",
    "    index_name=index_name \n",
    ")\n",
    "\n",
    "# Configuração do modelo\n",
    "llm = ChatOpenAI(   \n",
    "    model='gpt-3.5-turbo',  \n",
    "    temperature=0.0  \n",
    ")  \n",
    "\n",
    "# Configuração de mecanismo de perguntas e respostas\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(  \n",
    "    llm=llm,  \n",
    "    chain_type=\"stuff\",  \n",
    "    retriever=vectorstore.as_retriever()  \n",
    ")  \n",
    "\n",
    "qa_with_sources = RetrievalQAWithSourcesChain.from_chain_type(  \n",
    "    llm=llm,  \n",
    "    chain_type=\"stuff\",  \n",
    "    retriever=vectorstore.as_retriever()  \n",
    ")\n",
    "\n",
    "contexto = \"\\n\".join(texts) \n",
    "\n",
    "# Prompt aprimorado para respostas detalhadas e passo a passo\n",
    "prompt = f\"\"\"\n",
    "Use apenas as informações abaixo para responder a pergunta do usuário. Seja detalhado, em formato de passo a passo.\\n\\n{context}\n",
    "\n",
    "Baseado no seguinte contexto:\n",
    "{contexto}\n",
    "\n",
    "Responda à pergunta:\n",
    "{pergunta}\n",
    "\n",
    "Formato esperado:\n",
    "1. Passo 1: [descrição detalhada]\n",
    "2. Passo 2: [descrição detalhada]\n",
    "...\n",
    "\n",
    "Se a resposta não estiver no contexto acima, responda: 'Não encontrei essa informação no material disponível.'\n",
    "\"\"\"\n",
    "\n",
    "# Consulta para buscar informações\n",
    "pergunta = \"Como faço para configurar ao central para o cliente?\"\n",
    "\n",
    "pergunta_com_contexto = prompt\n",
    "\n",
    "resposta = llm(pergunta_com_contexto)\n",
    "\n",
    "display(Markdown(resposta.content))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
