{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "from pinecone import Pinecone\n",
    "from IPython.display import display, Markdown\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from openai import OpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain.chains import RetrievalQA, RetrievalQAWithSourcesChain\n",
    "from pinecone import ServerlessSpec\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "pc = Pinecone(api_key)\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"ia-sensor\"\n",
    "\n",
    "if not pc.has_index(index_name):\n",
    "   pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=1536,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(\n",
    "            cloud='aws',\n",
    "            region='us-east-1'\n",
    "        )\n",
    "    )\n",
    "    \n",
    "while not pc.describe_index(index_name).status['ready']:\n",
    "    time.sleep(1)\n",
    "\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sem prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Para configurar a central ITG200-K para o cliente, siga os seguintes passos:\n",
       "\n",
       "1. Acesse a interface gráfica da central utilizando o login e senha fornecidos.\n",
       "2. Na lateral esquerda, acesse a opção \"About\" para confirmar o SN e MAC Address do equipamento.\n",
       "3. Confirme se a central está correta e acesse as opções \"Network\" e \"Ethernet\".\n",
       "4. Na opção \"Ethernet\", insira as configurações solicitadas de acordo com o tipo de rede (DHCP ou estática).\n",
       "5. Para redes permitidas DHCP, habilite a opção DHCP, salve e aplique o reboot.\n",
       "6. Para redes estáticas, desabilite o DHCP e configure o IP, Netmask e Default Gateway.\n",
       "7. Salve as informações e não aplique o reboot conforme solicitado pelo console.\n",
       "8. Na opção DNS, insira as informações no DNS fixo \"Edit Fixed IP DNS Configuration\".\n",
       "9. Salve as informações e aplique o reboot no console.\n",
       "10. Após o reboot, verifique no display da central se o IP configurado aparece e conecte o cabo de rede no ponto liberado.\n",
       "\n",
       "Certifique-se de seguir corretamente as instruções e salvar as configurações antes de aplicar o reboot. Se tiver dúvidas ou encontrar dificuldades durante o processo, consulte o procedimento operacional padrão ou entre em contato com o suporte técnico responsável."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Upload do PDFs\n",
    "file = \"files/POP E OPR - 00X.00 - Central ITG 200K - Configuração de Rede .docx (1).pdf\"\n",
    "loader = PyMuPDFLoader(file)\n",
    "docs = loader.load()\n",
    "\n",
    "# Extrair texto dos documentos\n",
    "texts = []\n",
    "for doc in docs:\n",
    "    texts.append(doc.page_content)\n",
    "\n",
    "# Dividir texto em chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"],\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "split_texts = text_splitter.split_documents(docs)\n",
    "\n",
    "# Gera embeddings\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# Criação do armazenamento vetorial no Pinecone\n",
    "vectorstore = PineconeVectorStore.from_documents(\n",
    "    documents=split_texts, \n",
    "    embedding=embeddings, \n",
    "    index_name=index_name \n",
    ")\n",
    "\n",
    "# Configuração do modelo\n",
    "llm = ChatOpenAI(   \n",
    "    model='gpt-3.5-turbo',  \n",
    "    temperature=0.0  \n",
    ")  \n",
    "\n",
    "#  Configuração de mecanismo de perguntas e respostas\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(  \n",
    "    llm=llm,  \n",
    "    chain_type=\"stuff\",  \n",
    "    retriever=vectorstore.as_retriever()  \n",
    ")  \n",
    "\n",
    "qa_with_sources = RetrievalQAWithSourcesChain.from_chain_type(  \n",
    "    llm=llm,  \n",
    "    chain_type=\"stuff\",  \n",
    "    retriever=vectorstore.as_retriever()  \n",
    ")\n",
    "\n",
    "contexto = \"\\n\".join(texts) \n",
    "\n",
    "# Consulta para buscar informações\n",
    "pergunta = \"Como faço para congifurar a central para o cliente?\"\n",
    "\n",
    "pergunta_com_contexto = f\"Contexto:\\n{contexto}\\n\\nPergunta: {pergunta}\"\n",
    "\n",
    "resposta = llm(pergunta_com_contexto)\n",
    "\n",
    "display(Markdown(resposta.content)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Com prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "1. Passo 1: Para configurar a central para o cliente, é necessário primeiro acessar a interface gráfica da central ITG200-K.\n",
       "2. Passo 2: Realize o login utilizando as credenciais corretas.\n",
       "3. Passo 3: Após o login, na lateral esquerda da interface, clique em \"About\" para confirmar o Serial Number (SN) e o MAC Address do equipamento acessado.\n",
       "4. Passo 4: Confirmando que está na central correta, acesse as opções \"Network\" e depois \"Ethernet\".\n",
       "5. Passo 5: Na opção \"Ethernet\", insira as configurações solicitadas de acordo com o tipo de rede.\n",
       "   5.1. Para redes permitidas DHCP, habilite a opção DHCP, salve e aplique o Reboot.\n",
       "   5.2. Para redes estáticas, desabilite o DHCP e configure o IP, Netmask (Máscara) e Default Gateway.\n",
       "6. Passo 6: Após inserir as informações corretamente, salve as configurações.\n",
       "7. Passo 7: Não aplique o Reboot conforme solicitado pelo console.\n",
       "8. Passo 8: Na instrução DNS, insira as informações no DNS fixo \"Edit Fixed IP DNS Configuration\".\n",
       "9. Passo 9: Confira as informações inseridas e salve.\n",
       "10. Passo 10: Aplique o Reboot no console.\n",
       "11. Passo 11: Após o Reboot, verifique no display da central se o IP configurado aparece e conecte o cabo de rede no ponto liberado.\n",
       "\n",
       "Não encontrei essa informação no material disponível."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Upload do PDFs\n",
    "file = \"files/POP E OPR - 00X.00 - Central ITG 200K - Configuração de Rede .docx (1).pdf\"\n",
    "loader = PyMuPDFLoader(file)\n",
    "docs = loader.load()\n",
    "\n",
    "# Extrair texto dos documentos\n",
    "texts = []\n",
    "for doc in docs:\n",
    "    texts.append(doc.page_content)\n",
    "\n",
    "# Dividir texto em chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"],\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "split_texts = text_splitter.split_documents(docs)\n",
    "\n",
    "# generate unique id's\n",
    "\n",
    "i = 0\n",
    "uuids = []\n",
    "\n",
    "while i < len(split_texts):\n",
    "\n",
    "    i += 1\n",
    "\n",
    "    uuids.append(f\"id{i}\")\n",
    "\n",
    "# add to database\n",
    "\n",
    "vectorstore.add_documents(documents=split_texts, ids=uuids)\n",
    "\n",
    "# Gera embeddings\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# Criação do armazenamento vetorial no Pinecone\n",
    "vectorstore = PineconeVectorStore.from_documents(\n",
    "    documents=split_texts, \n",
    "    embedding=embeddings, \n",
    "    index_name=index_name \n",
    ")\n",
    "\n",
    "# Configuração do modelo\n",
    "llm = ChatOpenAI(   \n",
    "    model='gpt-3.5-turbo',  \n",
    "    temperature=0.0  \n",
    ")  \n",
    "\n",
    "# Configuração de mecanismo de perguntas e respostas\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(  \n",
    "    llm=llm,  \n",
    "    chain_type=\"stuff\",  \n",
    "    retriever=vectorstore.as_retriever()  \n",
    ")  \n",
    "\n",
    "qa_with_sources = RetrievalQAWithSourcesChain.from_chain_type(  \n",
    "    llm=llm,  \n",
    "    chain_type=\"stuff\",  \n",
    "    retriever=vectorstore.as_retriever()  \n",
    ")\n",
    "\n",
    "contexto = \"\\n\".join(texts) \n",
    "\n",
    "# Prompt aprimorado para respostas detalhadas e passo a passo\n",
    "prompt = f\"\"\"\n",
    "Você é um assistente altamente especializado em responder dúvidas com base **exclusivamente** nas informações fornecidas no contexto.  \n",
    "\n",
    "### **Diretrizes para sua resposta:**\n",
    "- **Extraia e interprete** os dados do contexto de maneira inteligente e detalhada.  \n",
    "- **Explique de forma clara**, organizada e estruturada, garantindo que qualquer pessoa possa compreender.  \n",
    "- **Utilize um formato passo a passo**, descrevendo cada etapa com precisão.  \n",
    "- Se houver conceitos importantes, forneça explicações adicionais e exemplos práticos.  \n",
    "- Caso a informação necessária **não esteja no contexto**, deixe isso claro e **não invente** respostas ou especule.  \n",
    "\n",
    "### **Contexto fornecido:**\n",
    "{contexto}\n",
    "\n",
    "### **Pergunta:**\n",
    "{pergunta}\n",
    "\n",
    "### **Formato esperado da resposta:**\n",
    "1. **Análise Inicial**  \n",
    "   - [Explique como a pergunta se relaciona ao contexto]  \n",
    "2. **Extração e Interpretação dos Dados**  \n",
    "   - [Destaque as informações relevantes do contexto]  \n",
    "3. **Passo a Passo da Resolução**  \n",
    "   - **Passo 1:** [Explicação detalhada]  \n",
    "   - **Passo 2:** [Explicação detalhada]  \n",
    "   - ...  \n",
    "4. **Conclusão e Recomendações**  \n",
    "   - [Resumo final com insights úteis]  \n",
    "\n",
    "Caso não encontre a resposta no contexto, responda:  \n",
    "*\"Não encontrei informações suficientes no contexto para responder com precisão.\"*  \n",
    "\n",
    "Seja claro, objetivo e didático em suas explicações.  \n",
    "\"\"\"\n",
    "\n",
    "# Consulta para buscar informações\n",
    "pergunta = \"Como faço para configurar ao central para o cliente em campo?\"\n",
    "\n",
    "pergunta_com_contexto = prompt\n",
    "\n",
    "resposta = llm(pergunta_com_contexto)\n",
    "\n",
    "display(Markdown(resposta.content))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
