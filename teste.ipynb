{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from IPython.display import display, Markdown\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "import os\n",
    "from pinecone import Pinecone \n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from pinecone import ServerlessSpec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "pc = Pinecone(api_key)\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"ia-sensor\"\n",
    "\n",
    "if not pc.has_index(index_name):\n",
    "   pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=1536,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(\n",
    "            cloud='aws',\n",
    "            region='us-east-1'\n",
    "        )\n",
    "    )\n",
    "    \n",
    "while not pc.describe_index(index_name).status['ready']:\n",
    "    time.sleep(1)\n",
    "\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Para configurar a central para o cliente, siga os passos descritos abaixo:\n",
       "\n",
       "Passo 1: Acesso ao PUTTY\n",
       "- Abra o PUTTY para se conectar à central. Insira o endereço IP e a porta de acesso necessária.\n",
       "\n",
       "Passo 2: Configuração da Central\n",
       "1. Execute o comando sensorgw appConfig\n",
       "2. Responda se é uma configuração de servidor padrão (Default server configuration) digitando 'y'\n",
       "3. Preencha as informações solicitadas:\n",
       "   - Client WebApp: Insira o nome do cliente (por exemplo, \"TESTE\")\n",
       "   - Client Login: Insira o login do cliente\n",
       "   - Client Password: Insira a senha do cliente\n",
       "   - CheckConnection: Deixe em branco\n",
       "   - CheckModem: Deixe em branco\n",
       "   - Carrier: Insira o nome da operadora\n",
       "\n",
       "Passo 3: Sincronização e Parada do Serviço\n",
       "- Execute os comandos:\n",
       "1. sync\n",
       "2. sensorgw stop\n",
       "\n",
       "Passo 4: Configuração do Hamachi\n",
       "- Continue o acesso ao PUTTY e siga a sequência de comandos a seguir.\n",
       "\n",
       "Passo 5: Parar o Serviço do Hamachi\n",
       "- Execute o comando: /etc/init.d/logmein-hamachi stop\n",
       "\n",
       "Passo 6: Remover Configurações Prévias do Hamachi\n",
       "- Execute o comando: rm -Rf /var/lib/logmein-hamachi/\n",
       "\n",
       "Passo 7: Iniciar o Serviço do Hamachi\n",
       "- Execute o comando: /etc/init.d/logmein-hamachi start\n",
       "\n",
       "Passo 8: Fazer Login no Hamachi\n",
       "- Execute o comando: hamachi login\n",
       "\n",
       "Passo 9: Definir o Nome da Central no Hamachi\n",
       "- Execute o comando: hamachi set-nick “CLIENTE” (substitua \"CLIENTE\" pelo nome desejado)\n",
       "\n",
       "Passo 10: Vincular a Conta do Hamachi\n",
       "- Execute o comando: hamachi attach eduardosleal@mcasistemas.com.br\n",
       "\n",
       "Passo 11: Conectar na Conta do Hamachi\n",
       "- Execute o comando: hamachi do-join 158-893-675 (substitua os números pelo ID adequado)\n",
       "- Quando solicitado, insira a senha: mcaUser\n",
       "\n",
       "Após seguir esses passos, a central estará configurada para enviar os dados ao portal do cliente corretamente. Certifique-se de inserir as informações corretas solicitadas e de substituir os dados genéricos mostrados no exemplo pelos dados reais do cliente."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file = \"files/Configuração e teste - Central SensorGW.pdf\"\n",
    "loader = PyMuPDFLoader(file)\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"],\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "split_texts = text_splitter.split_documents(docs)\n",
    "\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-ada-002\"\n",
    ")\n",
    "\n",
    "vectorstore = PineconeVectorStore.from_documents(\n",
    "    documents=split_texts, \n",
    "    embedding=embeddings, \n",
    "    index_name=index_name \n",
    ")\n",
    "\n",
    "\n",
    "#Retriver\n",
    "retriever = vectorstore.as_retriever()\n",
    "# Pegar os documentos relevantes baseado na pergunta\n",
    "pergunta = \"Como faço para congifurar a central para o cliente?\"\n",
    "docs_relevantes = retriever.invoke(pergunta)\n",
    "\n",
    "# Preparar o contexto\n",
    "context_list = []\n",
    "for doc in docs_relevantes:\n",
    "    context_list.append(doc.page_content)\n",
    "\n",
    "context = \"\\n\\n\".join(context_list)\n",
    "\n",
    "# Instanciando o modelo de IA e enviando a pergunta\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo-0125\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \n",
    "         \"content\": f\"Use apenas as informações abaixo para responder a pergunta do usuário. Seja detalhado, em formato de passo a passo.\\n\\n{context}\"\n",
    "         },\n",
    "        {\"role\": \"user\", \n",
    "        \"content\": f\"Baseado no seguinte contexto:\\n\\n{context}\\n\\nResponda à pergunta: {pergunta}\"\n",
    "         } \n",
    "    ]\n",
    ")\n",
    "\n",
    "# Resposta\n",
    "display(Markdown(completion.choices[0].message.content))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
