{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.schema import SystemMessage\n",
    "import numpy as np\n",
    "from IPython.display import display, Markdown\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "import os\n",
    "from pinecone import Pinecone \n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_pinecone import PineconeVectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "pc = Pinecone(api_key)\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"ia-sensor\"\n",
    "\n",
    "if not pc.has_index(index_name):\n",
    "   pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=1536,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(\n",
    "            cloud='aws',\n",
    "            region='us-east-1'\n",
    "        )\n",
    "    )\n",
    "    \n",
    "while not pc.describe_index(index_name).status['ready']:\n",
    "    time.sleep(1)\n",
    "\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Para configurar a central para o cliente, seguindo o padrão apresentado acima, siga os passos detalhados a seguir:\n",
       "\n",
       "1. Acesse a central via PUTTY.\n",
       "\n",
       "2. Execute o comando para iniciar a configuração da central:\n",
       "   \n",
       "   ```\n",
       "   sensorgw appConfig\n",
       "   ``` \n",
       "   - Responda se é uma configuração de servidor padrão (Default server configuration) pressionando \"y\".\n",
       "   - Indique o nome da aplicação web do cliente (Client WebApp), por exemplo, \"TESTE\".\n",
       "   - Preencha as informações solicitadas para o cliente: Client Login, Client Password, CheckConnection, CheckModem, e o nome da operadora (Carrier).\n",
       "\n",
       "3. Execute os comandos para sincronizar e parar a central:\n",
       "   \n",
       "   ```\n",
       "   sync\n",
       "   sensorgw stop\n",
       "   ```\n",
       "\n",
       "4. Realize a configuração do serviço HAMACHI:\n",
       "\n",
       "   - Pare o serviço do Hamachi:\n",
       "     ```\n",
       "     /etc/init.d/logmein-hamachi stop\n",
       "     ```\n",
       "\n",
       "   - Remova as configurações prévias do Hamachi:\n",
       "     ```\n",
       "     rm -Rf /var/lib/logmein-hamachi/\n",
       "     ```\n",
       "\n",
       "   - Inicie o serviço do Hamachi:\n",
       "     ```\n",
       "     /etc/init.d/logmein-hamachi start\n",
       "     ```\n",
       "\n",
       "5. Realize o login no Hamachi:\n",
       "   \n",
       "   ```\n",
       "   hamachi login\n",
       "   ```\n",
       "\n",
       "6. Defina o nome da central para o Hamachi:\n",
       "   \n",
       "   ```\n",
       "   hamachi set-nick “CLIENTE”\n",
       "   ```\n",
       "\n",
       "7. Vincule a conta do Hamachi:\n",
       "   \n",
       "   ```\n",
       "   hamachi attach eduardosleal@mcasistemas.com.br\n",
       "   ```\n",
       "\n",
       "8. Conecte-se à conta do Hamachi:\n",
       "   \n",
       "   ```\n",
       "   hamachi do-join 158-893-675\n",
       "   ```\n",
       "\n",
       "   - Será solicitada a senha, que no caso é \"mcaUser\".\n",
       "\n",
       "Dessa forma, seguindo esses passos, você conseguirá configurar a central para envio de dados ao portal do cliente de acordo com as instruções fornecidas no contexto."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file = \"files/Configuração e teste - Central SensorGW.pdf\"\n",
    "loader = PyMuPDFLoader(file)\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\\n\",\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "split_texts = text_splitter.split_documents(docs)\n",
    "\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-ada-002\"\n",
    ")\n",
    "\n",
    "vectorstore = PineconeVectorStore.from_documents(\n",
    "    documents=split_texts, \n",
    "    embedding=embeddings, \n",
    "    index_name=index_name \n",
    ")\n",
    "\n",
    "\n",
    "#Retriver\n",
    "retriever = vectorstore.as_retriever()\n",
    "# Pegar os documentos relevantes baseado na pergunta\n",
    "pergunta = \"Como faço para congifurar a central para o cliente?\"\n",
    "docs_relevantes = retriever.invoke(pergunta)\n",
    "\n",
    "# Preparar o contexto\n",
    "context_list = []\n",
    "for doc in docs_relevantes:\n",
    "    context_list.append(doc.page_content)\n",
    "\n",
    "context = \"\\n\\n\".join(context_list)\n",
    "\n",
    "# Instanciando o modelo de IA e enviando a pergunta\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo-0125\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \n",
    "         \"content\": f\"Use apenas as informações abaixo para responder a pergunta do usuário. Seja detalhado, em formato de passo a passo.\\n\\n{context}\"\n",
    "         },\n",
    "        {\"role\": \"user\", \n",
    "        \"content\": f\"Baseado no seguinte contexto:\\n\\n{context}\\n\\nResponda à pergunta: {pergunta}\"\n",
    "         } \n",
    "    ]\n",
    ")\n",
    "\n",
    "# Resposta\n",
    "display(Markdown(completion.choices[0].message.content))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
